{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# C Interpreter\n",
    "\n",
    "# Fourth Stage\n",
    "\n",
    "Design a grammar using an upward translator that accepts the following inputs from the C language:\n",
    "- scanf\n",
    "- main function of C language\n",
    "- void functions of C language\n",
    "\n",
    "To develop this we will divide de problem in 3 parts. First we will develop the lexical and grammar analyzer of *scanf* *main* function statement, then the *void* function and to finish we will introduce the semantic rules and the way to read the program from a file in python.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Grammar Definition for scanf\n",
    "\n",
    "The basic structure of *scanf* is:\n",
    "\n",
    "```c\n",
    " scanf(\"%type\", &variable_name);\n",
    "````\n",
    "\n",
    "And we can use with multiple values:\n",
    "\n",
    "```c\n",
    " scanf(\"%type %type %type\", &variable_name, &variable_name, &variable_name);\n",
    "````\n",
    "\n",
    "\n",
    "We can represent this with the following grammar:\n",
    "- exprscanf <- SCANF `(` scanfbody `)` `;`\n",
    "- scanfbody <- `\"` `%`TYPE scanbody`,` `&`ID\n",
    "- scanbody <- `\"`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Implementing the Lexical Analyzer (Lexer)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "class ScanLexer(Lexer):\n",
    "    tokens = {SCANF, TYPE, ID}\n",
    "    literals = {'(', ')', '%', '&'}\n",
    "\n",
    "    # Ignore whitespaces and tabs\n",
    "\n",
    "    ignore = ' \\t'\n",
    "\n",
    "    # Regular expressions for tokens\n",
    "\n",
    "    TYPE = r'%[sdfc]'\n",
    "    ID = r'[a-zA-Z][\\w_]*'\n",
    "\n",
    "    @_(r'\\d+')\n",
    "    def CNUM(self, t):\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    # Error handling rule\n",
    "\n",
    "    def error(self, t):\n",
    "        print('<-'*10,\"Illegal character '{}'\".format(t.value[0]), '->'*10)\n",
    "        self.index += 1\n",
    "        t.type='Illegal'\n",
    "        t.value =t.value[0]\n",
    "        return t"
   ]
  },
  {
   "source": [
    "## Testing lexical Analyzer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     scanf_sentences\n",
       "0  scanf(\"%d %d %d %d\", &minx, &maxx, &miny, &maxy);\n",
       "1  scanf(\"%s %d %f %c\", &var1, &var2, &var3, &var4);\n",
       "2                                 scanf(\"%s\",&name);"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>scanf_sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>scanf(\"%d %d %d %d\", &amp;minx, &amp;maxx, &amp;miny, &amp;maxy);</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scanf(\"%s %d %f %c\", &amp;var1, &amp;var2, &amp;var3, &amp;var4);</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>scanf(\"%s\",&amp;name);</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('../assets/testing/scanf_sentences.csv', delimiter=\"'\")\n",
    "data[['scanf_sentences']]"
   ]
  }
 ]
}