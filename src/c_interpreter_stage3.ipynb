{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# C Interpreter\n",
    "\n",
    "# Third Stage\n",
    "\n",
    "Design a grammar using an a upward translator that accepts the following inputs from the C language:\n",
    "- `printf` functions from C language.\n",
    "\n",
    "Add the AST for arithmetic, logic and relation operators.\n",
    "\n",
    "To develop this we will desing the grammar that accepts `printf` statements and then implement the AST for arithmetic, logic and relation operators."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Grammar design: Printf statement\n",
    "\n",
    "We will start developing the *printf* statement:\n",
    "\n",
    "### C print statement (printf)\n",
    "\n",
    "In *C* the base structure of the print statement is:\n",
    "\n",
    "``` \n",
    "printf(\"string [%type]*\", [variable_name])\n",
    "```\n",
    "\n",
    "Could contains variables or not, and the numbers of tags must match the number of variables.\n",
    "\n",
    "- printexpr <- `PRINTF` `(` stringexpr printftail\n",
    "- printftrail <- `,` fact printftail\n",
    "- printftrail <- `)`  \n",
    "- stringexpr <- CSTRING\n",
    "- fact -> `-` fact\n",
    "- fact -> num\n",
    "- fact -> `ID`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Implementing the lexical analyzer (Lexer)\n",
    "\n",
    "We will reuse the main lexical analyzer implementation, adding the *printf* logic necessary to process the new rules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "class Scanner(Lexer):\n",
    "    tokens = {ID, CNUM, PRINTF, STYPE, CSTRING}\n",
    "    literals ={'(', ')',',',';'}\n",
    "\n",
    "    # Ignore whitespace and tabulations\n",
    "\n",
    "    ignore = ' \\t'\n",
    "\n",
    "    # Regular expressions rules for tokens\n",
    "\n",
    "    ID = r'[a-zA-Z][\\w_]*'\n",
    "    CSTRING = r'\\\"(\\\\.|[^\\\"])*\\\"'\n",
    "\n",
    "    # Special cases\n",
    "    ID['printf'] = PRINTF\n",
    "    CSTRING['%'] = STYPE\n",
    "\n",
    "    @_(r'\\d+')\n",
    "    def CNUM(self, t):\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    # Error handling rule\n",
    "\n",
    "    def error(self, t):\n",
    "        print('<-'*10,\"Illegal character '{}'\".format(t.value[0]), '->'*10)\n",
    "        self.index += 1\n",
    "        t.type='Illegal'\n",
    "        t.value =t.value[0]\n",
    "        return t"
   ]
  },
  {
   "source": [
    "## Testing lexical Analyzer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                printf_sentences\n",
       "0             printf(\"%d %d %d %d\", a, b, c, d);\n",
       "1                        printf(\"%d %f\", 8, 45);\n",
       "2  printf(\"the add is %d the sub is %f\", 8, 45);"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>printf_sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>printf(\"%d %d %d %d\", a, b, c, d);</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>printf(\"%d %f\", 8, 45);</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>printf(\"the add is %d the sub is %f\", 8, 45);</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('../assets/testing/printf_sentences.csv', delimiter=\"'\")\n",
    "data[['printf_sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n0 Lexically Testing sentence: 'printf(\"%d %d %d %d\", a, b, c, d);'\n--------------------------------------------------------------------------------\n type = 'PRINTF', value = 'printf'\n type = '(', value = '('\n type = 'CSTRING', value = '\"%d %d %d %d\"'\n type = ',', value = ','\n type = 'ID', value = 'a'\n type = ',', value = ','\n type = 'ID', value = 'b'\n type = ',', value = ','\n type = 'ID', value = 'c'\n type = ',', value = ','\n type = 'ID', value = 'd'\n type = ')', value = ')'\n type = ';', value = ';'\n--------------------------------------------------------------------------------\n1 Lexically Testing sentence: 'printf(\"%d %f\", 8, 45);'\n--------------------------------------------------------------------------------\n type = 'PRINTF', value = 'printf'\n type = '(', value = '('\n type = 'CSTRING', value = '\"%d %f\"'\n type = ',', value = ','\n type = 'CNUM', value = '8'\n type = ',', value = ','\n type = 'CNUM', value = '45'\n type = ')', value = ')'\n type = ';', value = ';'\n--------------------------------------------------------------------------------\n2 Lexically Testing sentence: 'printf(\"the add is %d the sub is %f\", 8, 45);'\n--------------------------------------------------------------------------------\n type = 'PRINTF', value = 'printf'\n type = '(', value = '('\n type = 'CSTRING', value = '\"the add is %d the sub is %f\"'\n type = ',', value = ','\n type = 'CNUM', value = '8'\n type = ',', value = ','\n type = 'CNUM', value = '45'\n type = ')', value = ')'\n type = ';', value = ';'\n"
     ]
    }
   ],
   "source": [
    "lexer = Scanner()\n",
    "sentences = data['printf_sentences'].values\n",
    "pass_or_not = []\n",
    "all_token_pass = True\n",
    "\n",
    "for index, sentence in enumerate(sentences):\n",
    "    print('-' * 80,\"{} Lexically Testing sentence: '{}'\".format(index, sentence),'-' * 80, sep='\\n')\n",
    "    for token in lexer.tokenize(sentence):\n",
    "        print(\" type = '{}', value = '{}'\".format(token.type, token.value))\n",
    "        if all_token_pass and 'Illegal' in token.type:\n",
    "            all_token_pass = False\n",
    "    \n",
    "    pass_or_not.append('Pass') if all_token_pass else pass_or_not.append('FAIL')\n",
    "    all_token_pass = True\n",
    "\n",
    "data['Test'] = pass_or_not"
   ]
  }
 ]
}