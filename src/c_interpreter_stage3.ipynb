{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# C Interpreter\n",
    "\n",
    "# Third Stage\n",
    "\n",
    "Design a grammar using an a upward translator that accepts the following inputs from the C language:\n",
    "- `printf` functions from C language.\n",
    "\n",
    "Add the AST for arithmetic, logic and relation operators.\n",
    "\n",
    "To develop this we will desing the grammar that accepts `printf` statements and then implement the AST for arithmetic, logic and relation operators."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Grammar design: Printf statement\n",
    "\n",
    "We will start developing the *printf* statement:\n",
    "\n",
    "### C print statement (printf)\n",
    "\n",
    "In *C* the base structure of the print statement is:\n",
    "\n",
    "``` \n",
    "printf(\"string [%type]*\", [variable_name])\n",
    "```\n",
    "\n",
    "Could contains variables or not, and the numbers of tags must match the number of variables.\n",
    "\n",
    "- printexpr <- `PRINTF` `(`stringfunc printftrail\n",
    "- printftrail <- `,`fact printftrail\n",
    "- printftrail <- `)`  \n",
    "- fact -> `-` fact\n",
    "- fact -> num\n",
    "- fact -> `ID`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Implementing the lexical analyzer (Lexer)\n",
    "\n",
    "We will reuse the main lexical analyzer implementation, adding the *printf* logic necessary to process the new rules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "class Scanner(Lexer):\n",
    "    tokens = {ID, CNUM, PRINTF, STYPE}\n",
    "    literals ={'(', ')'}\n",
    "\n",
    "    # Ignore whitespace and tabulations\n",
    "\n",
    "    ignore = ' \\t'\n",
    "\n",
    "    # Regular expressions rules for tokens\n",
    "\n",
    "    STYPE = r'%[sdfc]'\n",
    "    ID = r'[a-zA-Z][\\w_]*'\n",
    "\n",
    "    # Special cases\n",
    "    ID['printf'] = PRINTF\n",
    "\n",
    "    @_(r'\\d+')\n",
    "    def CNUM(self, t):\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    # Error handling rule\n",
    "\n",
    "    def error(self, t):\n",
    "        print('<-'*10,\"Illegal character '{}'\".format(t.value[0]), '->'*10)\n",
    "        self.index += 1\n",
    "        t.type='Illegal'\n",
    "        t.value =t.value[0]\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}